 URL : "https://github.com/datafibers-community/df_data_service/issues/174" TITLE : build hadoop/hive source BODY : we need to stream back the batch data spark to queue. 1. we can build a kafka connect to fetch hive tables hive tables > export to files - > file connect . to connect to the hive, we can use hive jdbc driver 2. we add such features in spark sql transform option 1 is considered better for now, any suggestions?
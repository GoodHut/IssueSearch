 URL : "https://github.com/ljvmiranda921/pyswarms/issues/33" TITLE : binary pso cost problem BODY : pyswarms version: 0.1.6a description the cost doesn't seem to monotonically decrease from one iteration to the next. it seems like the cost that should be returned each iteration as the best cost is the one that is the historically best across all particles, yet on some iterations the cost seems to jump up, and the final cost when the algorithm completes isn't the minimum cost it encountered and returned in previous iterations. when i reduce the inertia, the problem reduces but it's still there . that behavior suggests to me that the global best position is computed from only particles' current positions and not their past positions. that way, as particles become more likely to explore, they are more likely to move into and out of good solutions. could that be what's going on? that the global / social best positions are computed only on the current iteration and not on the history of found solutions? what i did cost function: python line_model = linearregression def rmse_particle pos : line_model.fit x_train_en.loc :, pos==1 , y_train pred = line_model.predict x_test_en.loc :, pos==1 return np.sqrt mean_squared_error pred, y_test def rmse_func positions : n_particles = positions.shape 0 j = rmse_particle positions i for i in range n_particles return np.array j optimization python initialize swarm, arbitrary options = {'c1': 0.5, 'c2': 0.5, 'w':0, 'k':30 , 'p':2} call instance of pso dimensions = num_en dimensions should be the number of features n_particles = 30 optimizer = ps.discrete.binarypso n_particles=n_particles, dimensions=dimensions, options=options optimizer.reset cost, pos = optimizer.optimize rmse_func, print_step=1, iters=300, verbose=2
 URL : "https://github.com/google/seq2seq/issues/163" TITLE : seq2seq hogs gpu memory BODY : seq2seq will reserve all the memory an all the gpu's for a machine, but will only utilize one of them. for example, ! http://i.imgur.com/rlj7fqe.png this is the default tensorflow behavior but i still think multi-gpu machines should be managed better. you could 1 configure tf to reserve only the memory it needs on a single gpu. this means users could pass a target gpu as a configuration param, and that multiple training runs could be run on the same machine. this can be done with something like gpu_options = tf.gpuoptions per_process_gpu_memory_fraction=0.2, allow_growth=true sess = tf.session config=tf.configproto device_count={ gpu :0},	gpu_options=gpu_options or os.environ 'cuda_visible_devices' = '0' or whichever device you would like to use gpu_options = tf.gpuoptions allow_growth=true sess = tf.session config=tf.configproto gpu_options=gpu_options, allow_soft_placement=true 2 do proper single machine, multi-gpu training
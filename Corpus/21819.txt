 URL : "https://github.com/liangguohun/HadoopSpark/issues/11" TITLE : hadoop yarn 运行 BODY : ~/.bashrc 补上下面 export hadoop_conf_dir=/usr/local/hadoop/etc/hadoop spark-submit --driver-memory 2g --class runwordcount --master yarn-client bin/wordcount.jar 运行后存在hdfs上 2、配置spark standalone环境变量 cp /usr/local/spark/conf/spark-env.sh.template /usr/local/spark/conf/spark-env.sh export spark_master_ip=master export spark_worker_cores=1 export spark_worker_memory=400m export spark_worker_instances=2 //相应内容看文档里头的注释 ssh data1 sudo mkdir /usr/local/spark sudo chown hduser:hduser /usr/local/spark exit sudo scp -r /usr/local/spark hduser@data2:/usr/local 如果没有改变所有者 the authenticity of host 'data2 192.168.56.102 ' can't be established. ecdsa key fingerprint is 83:b3:ca:a3:01:b6:d6:6e:ea:d7:e4:3a:e7:d9:02:28. are you sure you want to continue connecting yes/no ? yes warning: permanently added 'data2,192.168.56.102' ecdsa to the list of known hosts. hduser@data2's password: 即使输入也没有权限，不改变所有者尝试
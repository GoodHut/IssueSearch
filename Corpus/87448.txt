 URL : "https://github.com/numpy/numpy/issues/9622" TITLE : linalg norm for 1d arrays BODY : hi, trying to optimize a code of mine, i noticed that numpy was spending a significant amount of time computing vector i.e. 1d numpy array norms. looking a bit in detail, i realized that for 1d vectors and the l2 norm, np.linalg.norm is not performing the best it could do. calling np.sqrt np.inner a,a , where a is a 1d numpy array, is significantly faster. consider the following code : https://gist.github.com/benoitrosa/5087120222c38a6646dfc8e04cad5d1d for all tested sizes of 1d vectors, the norm function is approximatively 50% faster than np.linalg.norm. for 2d and 3d vectors, it is a tiny bit slower. that's probably due to the overhead in the norm function i.e. testing for array number of dimensions . i know this applies only for 1d arrays and for the l2 norm, but i feel like this is a common use for many numpy users. many there is room for improvement ? or maybe, if that's too specific for integrating into the numpy function, could it be specified in the doc that taking the square root of the inner product for 1d arrays is significantly faster than using np.linalg.norm ? for the record, ubuntu 16.04 x64 with numpy 1.13.0 on python 2.7.12 were used for testing.
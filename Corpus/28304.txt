 URL : "https://github.com/coreos/flannel/issues/820" TITLE : flannel not cleanup BODY : <!--- provide a general summary of the issue in the title above --> at first, i start a kubernetes cluster a using flannel with default 10.244.0.0. then i start a new kubernetes cluster b using flannel with 10.83.0.0. one day, i decide to tear down the cluster a and move all the nodes to cluster b. i cleanup all the nodes with kubeadm reset systemctl stop kubelet systemctl stop docker rm -rf /var/lib/cni/ rm -rf /var/lib/kubelet/ rm -rf /run/flannel rm -rf /etc/cni/ ifconfig cni0 down brctl delbr cni0 ifconfig flannel.1 down systemctl start docker then i join them into cluster b. expected behavior the cluster a nodes should have a flannel.1 like 10.83.x.x after joining cluster b. current behavior the cluster a nodes still have 10.244.x.x after joining cluster b. possible solution <!--- not obligatory, but suggest a fix/reason for the bug, --> <!--- or ideas how to implement the addition or change --> steps to reproduce for bugs <!--- provide a link to a live example, or an unambiguous set of steps to --> <!--- reproduce this bug. include code to reproduce, if relevant --> 1. start a kubernetes cluster a using flannel with default 10.244.0.0. 2. start a kubernetes cluster b using flannel with 10.83.0.0. 3. tear down cluster a and join all the nodes to cluster b context <!--- how has this issue affected you? what are you trying to accomplish? --> <!--- providing context helps us come up with a solution that is most useful in the real world --> your environment <!--- include as many relevant details about the environment you experienced the bug in --> flannel version: backend used e.g. vxlan or udp : etcd version: kubernetes version if used : operating system and version: link to your project optional : flannel: v0.8.0-amd64 etcd: 3.0.17
 URL : "https://github.com/wlandau-lilly/drake/issues/77" TITLE : drake do BODY : most of my development is done on my local machine, which chokes on datasets that most people wouldn't even think of as big data . one of the reasons that i was drawn to drake in the first place was the idea that i could segment my data, and let my machine work on each part individually, making checkpoints along the way so that if it does choke, i don't have to re-run the whole thing. so i wrote a series of functions that give me similar functionality to dplyr::do , but in drake. specifically, i've written drake_split and drake_unsplit commands, which output plans. this allows me to ~~horribly misuse~~ creatively exploit the analyses function to process my small data chunks in parallel, including tasks such as validating using assertr and cleaning. i've got the bones of this issue solved, but i don't want to turn it into a pr until i can write some tests and maybe a vignette or example hopefully later this week . mostly, i'm opening this to solicit requests for functionality and to put it on the roadmap for later milestones. current/planned features: - splits automatically: - x data.frame - x tibble - data.table it might do this, i haven't tested at all - x recombines automatically - x plays well with magrittr pipe - x plays well with multi-step pipechains ex: mtcars %>% head %>% drake_split - x respects dplyr groups - x attempts to distribute groups evenly by row count among slices - x can apply multiple steps of analysis to each parallel slice i use this to validate, clean, and then analyze each slice - offer a choice of using the dplyr of base functions for splitting/binding - documentation - roxygen docs - example script - vignette - unit tests for each feature
 URL : "https://github.com/pat-coady/trpo/issues/10" TITLE : scaler vs. batchnorm BODY : hi @pat-coady -- i was wondering why you use a custom scaler python object instead of standard batchnorm e.g. the tensorflow kind https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization ? wouldn't sticking a batchnorm layer onto the front of the policy net achieve the same thing, require less code and be compatible with tf savers? sorry if i am misunderstanding!
 URL : "https://github.com/Eve208/Predictions-for-Movie-Performance.md/issues/7" TITLE : midterm peer review BODY : this looks like a great start on the project. the initial data analysis that led to adopting a second dataset for a sort of cross validation. i think the assumption that the missing data was uniformly dispersed is a reasonable assumption, but i would like to see some explicit reasoning just as to why you assume you can treat it as such. the amount of data analysis and visualization you have done before starting the modeling aspect of the project demonstrates a good understanding of you data and that gives me confidence that, going forward, you should be able to recognize potential issues as they arise in the numbers. i especially liked the pre analysis done by plotting certain features— i.e. genre, imdb ranking— against revenue to get a sense of what sort of weights to expect in the generated model. i am concerned about the phrase “massive amount of data indicators”. i’m assuming this means the number of features in each data point. if this is the case, is the data wide? i’d like to know what sort of methods will be used to eliminate features if this is the case. human intuition is a great starting point say if there were a column for length of end credits, we wouldn’t expect that to play into revenue a ton , but can be remiss in handling unexpected trends. be wary of balancing understanding your data with fitting your results to your preconceptions rather that your data. overall a cool project! haven’t seen a lot like this before and i think, with certain subsets of the features that would be known pre-release, the results of this project could be used by studios or even theaters when deciding on films to support.
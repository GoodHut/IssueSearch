 URL : "https://github.com/fchollet/keras/issues/6161" TITLE : keras consistency issue BODY : hi guys, i am using keras 2.0.2 with tensorflow backend. i have read the previous issues in keras giving different results at every run. so i set my numpy seed initially like this : np.random.seed 1337 import tensorflow as tf tf.set_random_seed 1337 i want to run an lstm layer so i also initialized all the initializers to a fixed seed like this : lstm = lstm 300,activation='tanh', recurrent_activation='sigmoid', recurrent_initializer=keras.initializers.randomnormal mean=0.0, stddev=0.05, seed=33 , bias_initializer=keras.initializers.randomnormal mean=0.0, stddev=0.05, seed=33 , kernel_initializer=keras.initializers.randomnormal mean=0.0, stddev=0.05, seed=33 embeddings i have also set shuffle = false while fitting the model so that the input does not get shuffled and set the number of epochs to be 1. when i check the lstm weights, i get two different weights for two different runs. could you please let me know how to solve this issue? thanks in advance. @fchollet @mbhenry @dragoon @lukeyeager
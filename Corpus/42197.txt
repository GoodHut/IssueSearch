 URL : "https://github.com/ARM-software/ComputeLibrary/issues/191" TITLE : an efficiency problem BODY : hiï¼Œi tested the nedirectcovolutionlayerkernel.cpp and found that when the input channel and output channel goes bigger, the efficiency goes worse, about twice slower than openblas, i tested two convolution kernels with no padding input_size kernel_size stride arm_compute_library openblas 5x5x48 3x3x48x64 1 0.46ms 0.34ms 3x3x64 3x3x64x128 1 0.46ms 0.25ms this really costs too much time and i don't know why?
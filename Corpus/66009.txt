 URL : "https://github.com/pfackeldey/PineBanana/issues/2" TITLE : lstm generating network BODY : ich hab einfach mal das text generating neural network von einem keras example basierend auf tensorflow committet . das liest einen fließ text von nietzsche ein und predicted dann einen neuen. wir haben ja tweets und keinen fließtext, was zu einem problem führen könnte. wir müssten auch mal testen wie das tweets.txt genau geschrieben werden soll: python def filesave filename,content : with open filename, a as myfile: myfile.write content for tweet in tweets: words_intweet = getwords tweet filesave tweets.txt ,tweet+ hier könnte man die tweets auch anders als mit einem zeilenumbruch trennen. außerdem müssen natürlich die hyperparameter vom model batch_size und epochs angepasst werden: python for iteration in range 1, 60 : print print '-' 50 print 'iteration', iteration model.fit x, y, batch_size=128, epochs=1 laufzeit und präzision des trainings hängen sehr stark davon ab.
 URL : "https://github.com/gvlproject/cloudbridge/issues/76" TITLE : file integrity check BODY : maybe it would be useful if we could expose means of assessing the integrity of a file. i can think of the following scenarios: 1. check if a file is correctly uploaded to s3. for this, first calculate the file's checksum using a hash function e.g., md5, sha256 , then compare it with s3 generated checksum. if the two hash values match, then the file is correctly upload; otherwise retry uploading the file. 2. get a file's checksum without download the file e.g., see this https://stackoverflow.com/questions/26415923/boto-get-md5-s3-file . a good scenario for this would checking if a local copy match s3 version, if not, then a collaborator has changed the file, hence update the local copy. it seems boto is exposing md5 checksum of an object, however, i guess the challenge would be to 1 ensue if/how other providers expose checksum without downloading a file/object; 2 are all the providers use common hash function for checksum?
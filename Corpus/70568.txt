 URL : "https://github.com/Applied-GeoSolutions/lidar2dems/issues/35" TITLE : wicked huge voxel files BODY : this isn't a problem on our compute cluster but large files of 12-50 gb cause a severe bog-down when trying to do demonstration runs on a smaller system 16gb laptop . for example the first step of automated logging scripts is to read in the voxel file and perform a summary calculation across vertical levels, and this read will not complete on a maxed out 8gb linux vm on my macbook. from @f-sullivan i think i've heard there is a natural way to divide or re-divide these files spatially via tiles, but i don't understand the implications yet.
 URL : "https://github.com/charlesm93/math/issues/40" TITLE : ss event with addl >= 1 BODY : summary: not sure what the behavior should be for such an event, but need to figure it out. description: the ambiguity arises when rate != 0 and ii = 0 constant rate infusion , and amt != 0. first of, in the case of a constant rate infusion, amt will be ignored if addl = 0. maybe we should produce a warning message if he or she passes a non-zero amt? when addl != 0, the dosing regime that led to the steady state gets repeated at the end of the steady state. this leads to a prolonged steady state. for example, if amt = 1200, and rate = 150, a constant infusion begins when the steady state ends, and ends after 8 hours. as a result, the steady state is prolonged for 8 hours. the gradient with respect f biovar didn't get properly evaluated either i saw discrepancies of up to 15% between finite and automatic differentiation, not for the steady state event, but the subsequent ones . reproducible steps: in generalodemodel_test.cpp , run the second test, gencpt_one_ss_2, and set addl 0 = 10 any non-zero value works . this should cause the autodiff unit tests to fail. current version: stan v2.15.0 torsten v0.83beta
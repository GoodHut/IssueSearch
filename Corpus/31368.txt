 URL : "https://github.com/pytorch/pytorch/issues/977" TITLE : setattr for modules BODY : >>> import torch.nn as nn >>> l = nn.linear 1,2 >>> l.generator >>> l.generator = none >>> l.generator >>> l.generator = nn.linear 3,4 <--------------------line 254 of module.py >>> l.generator >>> vars l {'_backend': <torch.nn.backends.thnn.thnnfunctionbackend object at 0x7fe07e7edcc0>, '_parameters': ordereddict 'weight', parameter containing: 0.8059 -0.6782 torch.floattensor of size 2x1 , 'bias', parameter containing: 0.6400 -0.7639 torch.floattensor of size 2 , '_buffers': ordereddict , '_backward_hooks': ordereddict , '_forward_hooks': ordereddict , '_modules': ordereddict 'generator', linear 3 -> 4 , 'training': true, 'in_features': 1, 'out_features': 2, 'generator': none} right now, this fails silently. the setattr should at least return a key error like add_module would, though i would prefer being able to overwrite none with modules later on.
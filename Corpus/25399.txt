 URL : "https://github.com/at15/hadoop-spark-perf/issues/8" TITLE : yarn use container BODY : this is a big issue i didn't think about, and now too late to solve? real solution - monitoring container is possible, though i don't know how yarn make use of container - find the container - use perf inside container fallback - only monitor the node using perf, i.e. namenode, datanode - see how spark work - with yarn - without yarn
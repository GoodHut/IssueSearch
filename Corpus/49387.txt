 URL : "https://github.com/ibab/tensorflow-wavenet/issues/271" TITLE : thoughts on 'crackle' BODY : hi there, thanks for your work implementing this. i'm trying to see if i can use this in a scenario where i want to work with the idea of _extrapolating musical material_. unfortunately, my computer is too slow a last i7 laptop, but no gpu , i'm running now with one single audio file in corpus at default sr of 16 khz, getting 2 steps per minute. so i have this running for a day and half, but i don't see it converging fast enough; i mean, it captures the timbre of the sound, that's great, but there is a crackle in the results that doesn't seem to go away. here are some iterations: https://soundcloud.com/sciss/sets/269171-wavenet in particular, it's nice to see that the noise in iter 1200 disappears and the resonances start to come out. when i heard iter 2500 i thought, great, it's going to work out, the crackle is almost gone. but then in iter 4400, the crackle has become more prominent again. if i look at the waveform, it seems the system introduces small bursts at nyquist which i think are responsible for that crackling sound: http://i.imgur.com/wq97zu6.png any thoughts on that? also - i would like to change the algorithm in two ways: - do away with the 8-bit ùùÅ-law encoding, because that has really bad snr. i would prefer to work directly with floating point scalars. - allow it to operate on stereo- or multi-channel input. any thoughts on this? thanks!
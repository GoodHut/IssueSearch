 URL : "https://github.com/OpenNMT/OpenNMT-py/issues/64" TITLE : a strange problem BODY : hello guys, i have a strange problem here, if i use memoryefficientloss function to backward loss, the training seems to be normal but if i put the content of memoryefficientloss into trainepoch function and do not define extra memoryefficientloss function, the training will not converge, all other code are the same. can anyone tell me why ? any reply will be appreciated. and another question, i do know why the split operation to ouputs of the model can save the memory, and why do you call the backward two times loss.backward and outputs.backward ? can you explain this ? thank you.